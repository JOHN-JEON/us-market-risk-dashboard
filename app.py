# -*- coding: utf-8 -*-
"""
ë¯¸êµ­ ì‹œì¥ ë¦¬ìŠ¤í¬ ì²´í¬í¬ì¸íŠ¸ â€“ ìë™ ëª¨ë‹ˆí„°ë§

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Streamlit ê¸°ë°˜ ëŒ€ì‹œë³´ë“œì…ë‹ˆë‹¤.

êµ¬ì„±:
1) ì…ë ¥ê°’ (Forward EPS, ê²½ê³  ê¸°ì¤€ì¹˜)
2) ì‹¤ì‹œê°„ ê·¼ì ‘ ì‹œì¥ ì§€í‘œ (S&P 500, VIX, HY OAS, Term Premium, UST10Y)
3) Auto check: ê° ì§€í‘œë¥¼ ê¸°ì¤€ê°’ê³¼ ë¹„êµí•´ OK/ê²½ê³  í‘œì‹œ
4) ì‹œì¥ ì‹¬ë¦¬ ì§€ìˆ˜ (ê³µí¬Â·íƒìš• ìŠ¤íƒ€ì¼ ìš”ì•½)
5) ë‰´ìŠ¤ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„° (í•µì‹¬ í…Œë§ˆë³„ ë‰´ìŠ¤ ìŠ¤ì½”ì–´ë§)

â€» API í‚¤ëŠ” .env íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
"""

import os
from math import isnan
from datetime import datetime, timedelta

import pandas as pd
import requests
import streamlit as st
import yfinance as yf
from dotenv import load_dotenv

# yfinanceê°€ Yahoo ì‘ë‹µ ë¬¸ì œë¡œ verboseí•œ ê²½ê³ ë¥¼ ë§ì´ ì°ì„ ìˆ˜ ìˆì–´
# ë¡œê·¸ ë ˆë²¨ì„ ì¤„ì—¬ ì½˜ì†”ì„ ê¹”ë”í•˜ê²Œ ìœ ì§€.
import logging
logging.getLogger("yfinance").setLevel(logging.ERROR)

# ---------------------
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ---------------------
load_dotenv()  # .env íŒŒì¼ì´ ìˆìœ¼ë©´ FRED_API_KEY, NEWS_API_KEY ë“±ì„ ì½ì–´ì˜´

# ---------------------
# Config
# ---------------------
FRED_API_KEY = os.getenv("FRED_API_KEY", "")
FRED_BASE = "https://api.stlouisfed.org/fred/series/observations"

# FREDì—ì„œ ê°€ì ¸ì˜¬ ì‹œê³„ì—´ ID ë§¤í•‘
FRED_SERIES = {
    "HY_OAS": "BAMLH0A0HYM2",          # í•˜ì´ì¼ë“œ íšŒì‚¬ì±„ OAS (ì‹ ìš©ìœ„í—˜ ì§€í‘œ)
    "TERM_PREMIUM_10Y": "THREEFYTP10",  # 10ë…„ë¬¼ Term Premium
    "UST10Y": "DGS10",                  # ë¯¸êµ­ 10ë…„ êµ­ì±„ê¸ˆë¦¬
    "SP500": "SP500",                   # S&P 500 ì§€ìˆ˜ (ë°±ì—…ìš©)
    "VIX": "VIXCLS",                    # VIX ì§€ìˆ˜ (ë°±ì—…ìš©)
}

# Yahoo Finance í‹°ì»¤
VIX_TICKER = "^VIX"
SPX_TICKER = "^GSPC"

# Auto checkì—ì„œ ì‚¬ìš©í•  ê¸°ì¤€ê°’
ALERTS = {
    "VIX": 25.0,
    "HY_OAS": 4.5,
    "TERM_PREMIUM_10Y": 0.9,
}

NEWS_API_KEY = os.getenv("NEWS_API_KEY")

# ---------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# ---------------------
st.set_page_config(page_title="ë¯¸êµ­ ì‹œì¥ ë¦¬ìŠ¤í¬ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ë¯¸êµ­ ì‹œì¥ ë¦¬ìŠ¤í¬ ì²´í¬í¬ì¸íŠ¸ â€“ ìë™ ëª¨ë‹ˆí„°ë§")
st.caption(
    "ë°ì´í„° ì¶œì²˜: FRED, Yahoo Finance. Forward P/Eì™€ ERPëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ EPSë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ìˆœ ê³„ì‚°ë©ë‹ˆë‹¤."
)

# ---------------------
# Helper Functions
# ---------------------
@st.cache_data(ttl=60 * 30)
def fred_series(series_id: str) -> pd.DataFrame:
    """
    FREDì—ì„œ ì‹œê³„ì—´ì„ ë¶ˆëŸ¬ì™€ DataFrameìœ¼ë¡œ ë°˜í™˜.
    - FRED_API_KEY ì—†ê±°ë‚˜ / ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ DataFrame ë°˜í™˜.
    - ì—¬ê¸°ì„œ ì‹¤íŒ¨í•´ë„ ì•± ì „ì²´ê°€ ì£½ì§€ ì•Šë„ë¡ ì˜ˆì™¸ë¥¼ ë‚´ë¶€ ì²˜ë¦¬.
    """
    if not FRED_API_KEY:
        return pd.DataFrame()

    params = {
        "series_id": series_id,
        "api_key": FRED_API_KEY,
        "file_type": "json",
        "observation_start": "2010-01-01",
    }

    try:
        r = requests.get(FRED_BASE, params=params, timeout=20)
        r.raise_for_status()
    except requests.exceptions.HTTPError as e:
        st.warning(f"{series_id} ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ FRED API ì˜¤ë¥˜: {e} (API í‚¤/ì¿¼í„° í™•ì¸ í•„ìš”).")
        return pd.DataFrame()
    except Exception as e:
        st.warning(f"{series_id} FRED ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

    data = r.json().get("observations", [])
    df = pd.DataFrame(data)
    if df.empty:
        return pd.DataFrame()

    df["date"] = pd.to_datetime(df["date"])
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df = df.set_index("date")[["value"]]
    df = df.rename(columns={"value": series_id})
    return df.dropna()


@st.cache_data(ttl=60 * 10)
def yf_latest(ticker: str) -> float:
    """
    Yahoo Financeì—ì„œ ìµœê·¼ ì¢…ê°€ë¥¼ ê°€ì ¸ì˜´. ì‹¤íŒ¨ ì‹œ NaN ë°˜í™˜.

    ì°¸ê³ :
    - íšŒì‚¬ ë„¤íŠ¸ì›Œí¬/ë°©í™”ë²½/VPN ë•Œë¬¸ì— Yahoo ì‘ë‹µì´ HTML/ë¹ˆê°’ìœ¼ë¡œ ì˜¬ ë•Œê°€ ìˆì–´
      yfinance ë‚´ë¶€ì—ì„œ JSONDecodeErrorë¥¼ ì¶œë ¥í•  ìˆ˜ ìˆìŒ.
    - ì—¬ê¸°ì„œëŠ” ì˜ˆì™¸ë¥¼ ë¨¹ê³  NaNì„ ëŒë ¤ì£¼ë©°,
      ì´í›„ ë¡œì§ì—ì„œ FRED ë°ì´í„°ë¡œ ë°±ì—…(fallback) ì‹œë„.
    """
    try:
        data = yf.download(
            ticker,
            period="5d",
            interval="1d",
            progress=False,
            auto_adjust=False,
        )
    except Exception:
        return float("nan")

    if data.empty:
        return float("nan")
    return float(data["Close"].dropna().iloc[-1])


@st.cache_data(ttl=60 * 10)
def yf_hist(ticker: str, period: str = "1y") -> pd.DataFrame:
    """Yahoo Financeì—ì„œ íˆìŠ¤í† ë¦¬ì»¬ ë°ì´í„°. ì‹¤íŒ¨ ì‹œ ë¹ˆ DataFrame."""
    try:
        return yf.download(
            ticker,
            period=period,
            interval="1d",
            progress=False,
            auto_adjust=False,
        )
    except Exception:
        return pd.DataFrame()


def traffic_light(value, threshold, higher_is_risk: bool = True):
    """
    ë‹¨ì¼ ê°’ê³¼ ê¸°ì¤€ê°’ì„ ë¹„êµí•´ ê°„ë‹¨í•œ 'ì •ìƒ/ê²½ê³ ' ì•„ì´ì½˜ì„ ë°˜í™˜.
    - higher_is_risk = True  â†’ ê°’ì´ í¬ë©´ ìœ„í—˜ (ì˜ˆ: VIX, HY OAS)
    - higher_is_risk = False â†’ ê°’ì´ ì‘ìœ¼ë©´ ìœ„í—˜ (ì˜ˆ: ERP)
    """
    if value is None or isnan(value):
        return "âšª", "ë°ì´í„° ì—†ìŒ"
    if higher_is_risk:
        return ("ğŸŸ¥", "ê²½ê³ ") if value >= threshold else ("ğŸŸ©", "ì •ìƒ")
    else:
        return ("ğŸŸ¥", "ê²½ê³ ") if value <= threshold else ("ğŸŸ©", "ì •ìƒ")


def vol_to_level(value: float) -> str:
    """
    VIX / VXN ìˆ˜ì¤€ì„ ê³µí¬Â·íƒìš• ë‹¨ê³„ë¡œ ë³€í™˜
    35â†‘      : ê³µí¬(ë§¤ìˆ˜)
    25~35    : ê³µí¬
    18~25    : ì¤‘ë¦½
    12~18    : íƒìš•
    12 ë¯¸ë§Œ  : íƒìš•(ë§¤ë„)
    """
    if value >= 35:
        return "ê³µí¬(ë§¤ìˆ˜)"
    elif value >= 25:
        return "ê³µí¬"
    elif value >= 18:
        return "ì¤‘ë¦½"
    elif value >= 12:
        return "íƒìš•"
    else:
        return "íƒìš•(ë§¤ë„)"


# ---------------------
# Inputs: ê°€ì •ì¹˜ ë° ì„ê³„ê°’
# ---------------------
st.markdown("---")
colA, colB, colC = st.columns(3)

with colA:
    # Forward EPSëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì…ë ¥í•˜ì§€ë§Œ,
    # ì¶”í›„ ìë™í™”(ì™¸ë¶€ API ì—°ë™)ë¥¼ ë¶™ì¼ ìˆ˜ ìˆë„ë¡ êµ¬ì¡°ë§Œ ë‹¨ìˆœí•˜ê²Œ ìœ ì§€.
    eps_forward = st.number_input(
        "S&P 500 í–¥í›„ 12ê°œì›” EPS (ì§ì ‘ ì…ë ¥)",
        min_value=0.0,
        value=260.0,
        step=5.0,
        help="ì»¨ì„¼ì„œìŠ¤ Forward EPS ì¶”ì •ì¹˜ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. "
             "ì¶”í›„ ì™¸ë¶€ ë°ì´í„° ì—°ë™ ì‹œ ì´ ê°’ì„ ìë™ìœ¼ë¡œ ì±„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

with colB:
    pe_threshold = st.number_input(
        "Forward P/E ê²½ê³  ê¸°ì¤€ê°’",
        min_value=10.0,
        value=23.0,
        step=0.5,
        help="ì´ ê°’ ì´ìƒì´ë©´ ë°¸ë¥˜ì—ì´ì…˜ ë¶€ë‹´(ê²½ê³ )ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.",
    )

with colC:
    erp_floor = st.number_input(
        "ERP (E/P - 10Y) ê²½ê³  ê¸°ì¤€ê°’ (%)",
        min_value=-5.0,
        value=0.0,
        step=0.1,
        help="ì´ ê°’ ì´í•˜ì´ë©´ 'ì£¼ì‹ ìœ„í—˜ ë³´ìƒì´ ë¶€ì¡±í•˜ë‹¤'ëŠ” ì‹ í˜¸ë¡œ í•´ì„í•©ë‹ˆë‹¤.",
    )

# ---------------------
# Live Data: ì‹œì¥ ì§€í‘œ
# ---------------------
st.markdown("---")
left, right = st.columns([2, 1])

with left:
    st.subheader("ì£¼ìš” ì‹œì¥ ì§€í‘œ (ì‹¤ì‹œê°„ì— ê·¼ì ‘)")
    st.caption("ë¯¸êµ­ ì£¼ì‹Â·ì±„ê¶ŒÂ·ì‹ ìš© ìŠ¤í”„ë ˆë“œ í•µì‹¬ ì§€í‘œë¥¼ ëª¨ì•„ í˜„ì¬ ì‹œì¥ í™˜ê²½ì„ í•œëˆˆì— ë³´ì—¬ì¤ë‹ˆë‹¤.")

    # FRED ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ (ë™ì¼ ìš”ì²­ ìºì‹œë¨)
    fred_dfs = {name: fred_series(sid) for name, sid in FRED_SERIES.items()}

    def last_value(name: str) -> float:
        """íŠ¹ì • ì‹œê³„ì—´ì˜ ê°€ì¥ ìµœê·¼ ê°’ë§Œ êº¼ë‚´ëŠ” í—¬í¼."""
        df = fred_dfs.get(name)
        if df is None or df.empty:
            return float("nan")
        col = df.columns[0]
        return float(df[col].dropna().iloc[-1])

    # S&P 500: 1ì°¨ëŠ” Yahoo, ì‹¤íŒ¨ ì‹œ FRED SP500ìœ¼ë¡œ ë°±ì—…
    spx = yf_latest(SPX_TICKER)
    if isnan(spx):
        v = last_value("SP500")
        if not isnan(v):
            spx = v  # Yahoo ë§‰í˜€ë„ ì§€ìˆ˜ ìˆ˜ì¤€ì€ FREDë¡œ ë³´ì •

    # VIX: 1ì°¨ëŠ” Yahoo, ì‹¤íŒ¨ ì‹œ FRED VIXCLSë¡œ ë°±ì—…
    vix = yf_latest(VIX_TICKER)
    if isnan(vix):
        v = last_value("VIX")
        if not isnan(v):
            vix = v

    # ê·¸ ì™¸ ì§€í‘œëŠ” FREDì—ì„œë§Œ ê°€ì ¸ì˜´
    hy_oas = last_value("HY_OAS")
    tp10 = last_value("TERM_PREMIUM_10Y")
    ust10 = last_value("UST10Y")

    # Forward P/E & ERP ê³„ì‚° (eps_forwardê°€ ìœ íš¨í•  ë•Œë§Œ)
    pe_forward = None
    erp = None
    if eps_forward and eps_forward > 0 and not isnan(spx):
        pe_forward = spx / eps_forward
        if not isnan(ust10):
            # ERP â‰ˆ E/P - 10Y (ë‹¨ìˆœ ê·¼ì‚¬)
            erp = (eps_forward / spx) * 100.0 - ust10

    # ìƒë‹¨ í•µì‹¬ ìˆ«ì 5ê°œ
    m1, m2, m3, m4, m5 = st.columns(5)
    m1.metric("S&P 500", f"{spx:,.0f}" if not isnan(spx) else "N/A")
    m2.metric("VIX", f"{vix:.1f}" if not isnan(vix) else "N/A")
    m3.metric("HY OAS (%)", f"{hy_oas:.2f}" if not isnan(hy_oas) else "N/A")
    m4.metric("10Y Term Premium (%)", f"{tp10:.2f}" if not isnan(tp10) else "N/A")
    m5.metric("UST 10Y (%)", f"{ust10:.2f}" if not isnan(ust10) else "N/A")

    st.write("â€”")
    c1, c2 = st.columns(2)

    with c1:
        st.caption("VIX (ìµœê·¼ 1ë…„) â€” ë³€ë™ì„±ì´ êµ¬ì¡°ì ìœ¼ë¡œ ë†’ì•„ì§€ëŠ”ì§€ ì²´í¬.")
        vix_hist = yf_hist(VIX_TICKER, period="1y")
        if not vix_hist.empty:
            st.line_chart(vix_hist["Close"])

    with c2:
        st.caption("HY OAS (ìµœê·¼ ìˆ˜ë…„) â€” ì‹ ìš© ìŠ¤í”„ë ˆë“œ í™•ëŒ€ ì—¬ë¶€ë¡œ ìœ„í—˜ ì„ í˜¸ ë³€í™” í™•ì¸.")
        df_hy = fred_dfs.get("HY_OAS")
        if df_hy is not None and not df_hy.empty:
            st.line_chart(df_hy.tail(2600))

with right:
    st.subheader("ìë™ ë¦¬ìŠ¤í¬ ì²´í¬")
    st.caption("ê° ì§€í‘œë¥¼ ì‚¬ì „ ê¸°ì¤€ê³¼ ë¹„êµí•´ 'ì •ìƒ/ê²½ê³ ' ì‹ í˜¸ë¥¼ ë‹¨ìˆœí™”í•´ ë³´ì—¬ì¤ë‹ˆë‹¤.")

    # VIX
    if not isnan(vix):
        icon, msg = traffic_light(vix, ALERTS["VIX"], higher_is_risk=True)
        st.write(f"**VIX**: {vix:.1f} â†’ {icon} {msg} (ê¸°ì¤€: {ALERTS['VIX']})")
    else:
        st.write("**VIX**: ë°ì´í„° ì—†ìŒ")

    # HY OAS
    if not isnan(hy_oas):
        icon, msg = traffic_light(hy_oas, ALERTS["HY_OAS"], higher_is_risk=True)
        st.write(f"**HY OAS**: {hy_oas:.2f}% â†’ {icon} {msg} (ê¸°ì¤€: {ALERTS['HY_OAS']}%)")
    else:
        st.write("**HY OAS**: ë°ì´í„° ì—†ìŒ")

    # Term Premium
    if not isnan(tp10):
        icon, msg = traffic_light(tp10, ALERTS["TERM_PREMIUM_10Y"], higher_is_risk=True)
        st.write(
            f"**10Y Term Premium**: {tp10:.2f}% â†’ {icon} {msg} "
            f"(ê¸°ì¤€: {ALERTS['TERM_PREMIUM_10Y']}%)"
        )
    else:
        st.write("**10Y Term Premium**: ë°ì´í„° ì—†ìŒ")

    # Forward P/E
    if pe_forward is not None:
        icon, msg = traffic_light(pe_forward, pe_threshold, higher_is_risk=True)
        st.write(
            f"**Forward P/E**: {pe_forward:.1f}ë°° â†’ {icon} {msg} "
            f"(ê¸°ì¤€: {pe_threshold}ë°°)"
        )
    else:
        st.write("**Forward P/E**: EPS ì…ë ¥ í•„ìš”")

    # ERP
    if erp is not None:
        icon, msg = traffic_light(erp, erp_floor, higher_is_risk=False)
        st.write(
            f"**ERP ì¶”ì •ì¹˜ (E/P - 10Y)**: {erp:.2f}% â†’ {icon} {msg} "
            f"(ê¸°ì¤€: {erp_floor}%)"
        )
    else:
        st.write("**ERP ì¶”ì •ì¹˜**: UST10Y ë° EPS í•„ìš”")

# ---------------------
# ì§€ìˆ˜ë³„ ì‹œì¥ ì‹¬ë¦¬ ì§€ìˆ˜ (ê³µí¬ì§€ìˆ˜ ê¸°ë°˜)
# ---------------------
st.markdown("---")
st.subheader("ì§€ìˆ˜ë³„ ì‹œì¥ ì‹¬ë¦¬ ì§€ìˆ˜ (ê³µí¬ì§€ìˆ˜ ê¸°ë°˜)")

st.caption(
    "S&P 500ì€ VIX, ë‚˜ìŠ¤ë‹¥ 100ì€ VXN ê³µí¬ì§€ìˆ˜ë¥¼ ì‚¬ìš©í•´ "
    "ê³µí¬(ë§¤ìˆ˜) â†” ê³µí¬ â†” ì¤‘ë¦½ â†” íƒìš• â†” íƒìš•(ë§¤ë„) ë‹¨ê³„ë¡œ ìš”ì•½í•©ë‹ˆë‹¤."
)

# VIX ê°’ì€ ìœ„ì—ì„œ ì´ë¯¸ ê³„ì‚°í•œ vix ì‚¬ìš© (Yahoo â†’ FRED ë°±ì—… ë¡œì§)
vix_value = None if isnan(vix) else float(vix)

# VXNì€ FREDì—ì„œ ì§ì ‘ í˜¸ì¶œ (VXNCLS)
df_vxn = fred_series("VXNCLS")
if df_vxn is not None and not df_vxn.empty:
    vxn_value = float(df_vxn["VXNCLS"].dropna().iloc[-1])
else:
    vxn_value = float("nan")

sentiment_data = {
    "S&P 500 (VIX)": vix_value,
    "ë‚˜ìŠ¤ë‹¥ 100 (VXN)": None if isnan(vxn_value) else vxn_value,
}

cols = st.columns(2)

for (index_name, value), col in zip(sentiment_data.items(), cols):
    with col:
        # ì§€ìˆ˜ ì´ë¦„
        st.markdown(
            f"<div style='font-size:16px; color:#555;'>{index_name}</div>",
            unsafe_allow_html=True,
        )

        if value is None:
            # ë°ì´í„° ì—†ì„ ë•Œ
            st.markdown(
                "<div style='font-size:32px; font-weight:600; margin-top:8px;'>ë°ì´í„° ì—†ìŒ</div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                "<div style='font-size:24px; color:#e53935; margin-top:4px;'>&darr;</div>",
                unsafe_allow_html=True,
            )
        else:
            level = vol_to_level(value)
            st.markdown(
                f"<div style='font-size:32px; font-weight:700; margin-top:8px;'>{level}</div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                f"<div style='font-size:18px; color:#666; margin-top:4px;'>ì§€ìˆ˜ ê°’: {value:.2f}</div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                "<div style='font-size:24px; color:#e53935; margin-top:4px;'>&darr;</div>",
                unsafe_allow_html=True,
            )

st.markdown(
    """
    <div style='font-size:13px; color:#777;'>
    ë‹¨ê³„: ê³µí¬(ë§¤ìˆ˜) &larr; ê³µí¬ &larr; ì¤‘ë¦½ &larr; íƒìš• &larr; íƒìš•(ë§¤ë„)  
    *êµ¬ê°„ ì˜ˆì‹œ: 35â†‘ ê³µí¬(ë§¤ìˆ˜), 25~35 ê³µí¬, 18~25 ì¤‘ë¦½, 12~18 íƒìš•, 12â†“ íƒìš•(ë§¤ë„)
    </div>
    """,
    unsafe_allow_html=True,
)

# ---------------------
# ë‰´ìŠ¤ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„° (Market News Risk Radar)
# ---------------------
st.markdown("---")
st.subheader("ë‰´ìŠ¤ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„° (Market News Risk Radar)")
st.caption(
    "AI íˆ¬ì, ê±°ì‹œ í™˜ê²½, ì‹ ìš© ìŠ¤íŠ¸ë ˆìŠ¤, ì§€ì •í•™ ë¦¬ìŠ¤í¬ ë“± í•µì‹¬ í…Œë§ˆë³„ë¡œ "
    "ìµœê·¼ 3ì¼ê°„ ê¸€ë¡œë²Œ ë‰´ìŠ¤ í†¤ì„ ê°„ë‹¨íˆ ìŠ¤ì½”ì–´ë§í•´ ì–´ë””ì— ë¦¬ìŠ¤í¬ê°€ ìŒ“ì´ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤."
)


def fetch_news(keywords, days=3, page_size=30):
    """
    NewsAPIë¥¼ ì´ìš©í•´ í‚¤ì›Œë“œ ê¸°ë°˜ ë‰´ìŠ¤ ê²€ìƒ‰.
    - NEWS_API_KEY ë¯¸ì„¤ì • ë˜ëŠ” ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜.
    - UI ìª½ì—ì„œ ì¡°ìš©íˆ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì—¬ê¸°ì„œ ì˜ˆì™¸ë¥¼ ì‚¼í‚µë‹ˆë‹¤.
    """
    if not NEWS_API_KEY:
        return []

    from_date = (datetime.utcnow() - timedelta(days=days)).strftime("%Y-%m-%d")
    query = " OR ".join([f'"{kw}"' for kw in keywords])

    params = {
        "q": query,
        "from": from_date,
        "language": "en",
        "sortBy": "publishedAt",
        "pageSize": page_size,
        "apiKey": NEWS_API_KEY,
    }

    try:
        resp = requests.get("https://newsapi.org/v2/everything", params=params, timeout=10)
        resp.raise_for_status()
        data = resp.json()
        return data.get("articles", [])
    except Exception:
        return []


def analyze_sentiment(articles):
    """
    ë§¤ìš° ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶€ì •/ê¸ì • ìŠ¤ì½”ì–´.
    - ë¶€ì • ë‹¨ì–´ê°€ ë§ì„ìˆ˜ë¡ score â†‘ â†’ ìœ„í—˜ ì¦ê°€.
    - ê¸ì • ë‹¨ì–´ëŠ” ì¼ë¶€ ìƒì‡„.
    """
    NEGATIVE_WORDS = ["cut", "slowdown", "delay", "freeze", "reduce", "weak", "down", "outflow", "default"]
    POSITIVE_WORDS = ["growth", "expansion", "increase", "record", "raise", "inflow", "strong"]

    total_score = 0
    for art in articles:
        text = (art.get("title", "") + " " + (art.get("description") or "")).lower()
        neg = sum(w in text for w in NEGATIVE_WORDS)
        pos = sum(w in text for w in POSITIVE_WORDS)
        total_score += max(0, neg - 0.5 * pos)

    if total_score <= 0:
        status = "âœ… ì–‘í˜¸"
        color = "green"
    elif total_score < 4:
        status = "ğŸŸ¡ ì£¼ì˜"
        color = "orange"
    else:
        status = "ğŸ”´ ê²½ê³ "
        color = "red"

    return status, color, total_score


# ëª¨ë‹ˆí„°ë§ í…Œë§ˆ ì„¤ì •: í•„ìš”ì‹œ í‚¤ì›Œë“œ ìˆ˜ì •í•´ì„œ ìš´ìš©
NEWS_TOPICS = {
    "AIÂ·ë°ì´í„°ì„¼í„° CapEx":
        ["AI capex slowdown", "data center capex cut", "hyperscaler capex", "NVIDIA order cut"],
    "ê±°ì‹œÂ·ê¸ˆë¦¬Â·ìœ ë™ì„±":
        ["rate hike", "rate cut", "bond market turmoil", "liquidity squeeze", "yield curve inversion"],
    "ì‹ ìš©Â·ë¶€ë„Â·ìœ ë™ì„± ê²½ìƒ‰":
        ["credit spread widening", "high yield stress", "default wave", "bank failure", "fund redemption"],
    "ì§€ì •í•™Â·ì›ìì¬Â·ì—ë„ˆì§€":
        ["geopolitical tension", "war", "sanctions", "oil price spike", "shipping disruption", "Red Sea crisis"],
}

if not NEWS_API_KEY:
    st.warning("âš ï¸ NEWS_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— NewsAPI í‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
else:
    cols = st.columns(len(NEWS_TOPICS))
    topic_results = []

    # 1) í…Œë§ˆë³„ ìš”ì•½ ë°•ìŠ¤
    for (topic, keywords), col in zip(NEWS_TOPICS.items(), cols):
        articles = fetch_news(keywords)
        if articles:
            status, color, score = analyze_sentiment(articles)
            topic_results.append((topic, status, color, score, articles))

            with col:
                st.markdown(f"**{topic}**")
                st.markdown(
                    f"<span style='color:{color}; font-weight:bold'>{status}</span>",
                    unsafe_allow_html=True,
                )
                st.caption(f"ê´€ë ¨ ê¸°ì‚¬ {len(articles)}ê±´ Â· ë¦¬ìŠ¤í¬ ìŠ¤ì½”ì–´ {score}")
        else:
            topic_results.append((topic, "ë°ì´í„° ë¶€ì¡±", "gray", 0, []))
            with col:
                st.markdown(f"**{topic}**")
                st.caption("ìµœê·¼ 3ì¼ê°„ ëšœë ·í•œ ê´€ë ¨ í‚¤ì›Œë“œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 2) ê°€ì¥ ìŠ¤ì½”ì–´ê°€ ë†’ì€(ë¶€ì • ë‰´ìŠ¤ê°€ ë§ì€) í…Œë§ˆ ìƒì„¸ í‘œì‹œ
    if any(tr[4] for tr in topic_results):
        worst_topic, worst_status, worst_color, worst_score, worst_articles = max(
            topic_results, key=lambda x: x[3]
        )

        if worst_articles and worst_score > 0:
            st.markdown("---")
            st.markdown(
                f"**í˜„ì¬ ê°€ì¥ ì£¼ì˜í•´ì•¼ í•  ì´ìŠˆ ì˜ì—­:** {worst_topic} â€” "
                f"<span style='color:{worst_color}; font-weight:bold'>{worst_status}</span> "
                f"(ìŠ¤ì½”ì–´ {worst_score})",
                unsafe_allow_html=True,
            )
            st.caption("í•´ë‹¹ ì˜ì—­ì—ì„œ ì„ ë³„í•œ ëŒ€í‘œ ê¸°ì‚¬ì…ë‹ˆë‹¤. í†¤ê³¼ ë¹ˆë„, ë§¥ë½ì„ í•¨ê»˜ í™•ì¸í•˜ì„¸ìš”.")

            for art in worst_articles[:5]:
                st.markdown(
                    f"- [{art['title']}]({art['url']}) â€” "
                    f"{art['source']['name']} ({art['publishedAt'][:10]})"
                )
    else:
        st.info("ëª¨ë‹ˆí„°ë§ëœ ì£¼ìš” ë¦¬ìŠ¤í¬ í…Œë§ˆì—ì„œ ëšœë ·í•œ ë¶€ì •ì  ë‰´ìŠ¤ ì¶•ì ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ---------------------
# ì£¼ìš” ì§€ìˆ˜ë³„ ìƒìœ„ 10ê°œ ì¢…ëª© ì§€í‘œ (Finnhub ê¸°ë°˜, ì‹œê°€ì´ì•¡ ìˆœì„œ + í•œê¸€ ì´ë¦„)
# ---------------------
st.markdown("---")
st.subheader("ğŸ›ï¸ ì£¼ìš” ì§€ìˆ˜ë³„ ìƒìœ„ 10ê°œ ì¢…ëª© í˜„í™© (Finnhub, ì‹œê°€ì´ì•¡ ìˆœ)")
st.caption(
    "ê° ì§€ìˆ˜ë³„ ì‹œê°€ì´ì•¡ ê¸°ì¤€ ìƒìœ„ 10ê°œ ëŒ€í‘œ ì¢…ëª©ì„ ê³ ì • ë¦¬ìŠ¤íŠ¸ë¡œ ë‘ê³ , "
    "Finnhub ë¬´ë£Œ APIì˜ /quote ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ê°€ê²©Â·ë“±ë½ë¥ ì„ í‘œì‹œí•©ë‹ˆë‹¤. "
    "ì¢…ëª© ì´ë¦„ì€ í•œêµ­ì–´(ì˜ë¬¸í‹°ì»¤) í˜•íƒœë¡œ í‘œê¸°í•©ë‹ˆë‹¤."
)

FINNHUB_API_KEY = os.getenv("FINNHUB_API_KEY", "").strip()

# âœ… ì‹œê°€ì´ì•¡ ìˆœì„œë¡œ ì •ë ¬ëœ ëŒ€í‘œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
INDEX_TOP10 = {
    "S&P 500": [
        "AAPL", "MSFT", "NVDA", "AMZN", "META",
        "GOOGL", "BRK.B", "TSLA", "UNH", "XOM"
    ],
    "Nasdaq 100": [
        "AAPL", "MSFT", "NVDA", "AMZN", "META",
        "GOOGL", "AVGO", "TSLA", "PEP", "COST"
    ],
    "Dow Jones": [
        "UNH", "MSFT", "GS", "HD", "MCD",
        "V", "CAT", "AMGN", "CRM", "AAPL"
    ],
    "Russell 2000": [
        "SMCI", "CELH", "APPF", "INSM", "RPD",
        "TMDX", "ENPH", "RUN", "BLDR", "IOT"
    ],
}

# âœ… í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
KOREAN_NAME_MAP = {
    "AAPL": "ì• í”Œ",
    "MSFT": "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "AMZN": "ì•„ë§ˆì¡´ë‹·ì»´",
    "NVDA": "ì—”ë¹„ë””ì•„",
    "GOOGL": "ì•ŒíŒŒë²³A",
    "META": "ë©”íƒ€ í”Œë«í¼ìŠ¤",
    "BRK.B": "ë²„í¬ì…” í•´ì„œì›¨ì´ B",
    "TSLA": "í…ŒìŠ¬ë¼",
    "UNH": "ìœ ë‚˜ì´í‹°ë“œí—¬ìŠ¤ê·¸ë£¹",
    "XOM": "ì—‘ì†ëª¨ë¹Œ",
    "AVGO": "ë¸Œë¡œë“œì»´",
    "PEP": "í©ì‹œì½”",
    "COST": "ì½”ìŠ¤íŠ¸ì½”",
    "GS": "ê³¨ë“œë§Œì‚­ìŠ¤",
    "HD": "í™ˆë””í¬",
    "MCD": "ë§¥ë„ë‚ ë“œ",
    "AMGN": "ì•”ì  ",
    "V": "ë¹„ì",
    "CAT": "ìºí„°í•„ëŸ¬",
    "CRM": "ì„¸ì¼ì¦ˆí¬ìŠ¤",
    "SMCI": "ìŠˆí¼ë§ˆì´í¬ë¡œ ì»´í“¨í„°",
    "CELH": "ì…€ì‹œì–´ìŠ¤ í™€ë”©ìŠ¤",
    "APPF": "ì•±í´ë¦¬ì˜¤",
    "INSM": "ì¸ìŠ¤ë©”ë“œ",
    "RPD": "ë˜í”¼ë“œ7",
    "TMDX": "íŠ¸ëœìŠ¤ë©”ë”•ìŠ¤",
    "ENPH": "ì—”í˜ì´ì¦ˆ ì—ë„ˆì§€",
    "RUN": "ì„ ëŸ°",
    "BLDR": "ë¹Œë”ìŠ¤ í¼ìŠ¤íŠ¸ì†ŒìŠ¤",
    "IOT": "ì†œí¬ë‚˜ìš°(IOT ê¸°ì—…)"
}

@st.cache_data(ttl=60)
def finnhub_quotes(symbols, token):
    """ì—¬ëŸ¬ ì¢…ëª©ì˜ /quote ë°ì´í„° í˜¸ì¶œ"""
    if not token:
        return pd.DataFrame()

    rows = []
    for sym in symbols:
        url = "https://finnhub.io/api/v1/quote"
        params = {"symbol": sym, "token": token}
        try:
            r = requests.get(url, params=params, timeout=6)
            r.raise_for_status()
            q = r.json()
        except Exception:
            continue

        c = q.get("c")  # current / close
        pc = q.get("pc")
        d = q.get("d")
        dp = q.get("dp")
        h = q.get("h")
        l = q.get("l")

        if not c and not pc:
            continue

        price = c if c not in (None, 0) else pc

        if d is None and price is not None and pc not in (None, 0):
            d = price - pc
        if dp is None and d is not None and pc not in (None, 0):
            dp = (d / pc) * 100

        display_name = KOREAN_NAME_MAP.get(sym, sym)
        rows.append({
            "ì¢…ëª©": f"{display_name} ({sym})",
            "ê°€ê²©": round(price, 2) if price is not None else None,
            "ë“±ë½(USD)": round(d, 2) if d is not None else None,
            "ë“±ë½ë¥ (%)": round(dp, 2) if dp is not None else None,
            "ê³ ê°€": round(h, 2) if h not in (None, 0) else None,
            "ì €ê°€": round(l, 2) if l not in (None, 0) else None,
        })

    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    return df


if not FINNHUB_API_KEY:
    st.error("âš ï¸ FINNHUB_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
else:
    for index_name, tickers in INDEX_TOP10.items():
        st.markdown(f"### ğŸ“ˆ {index_name} ìƒìœ„ 10ê°œ ì¢…ëª© (ì‹œê°€ì´ì•¡ ìˆœ)")

        df = finnhub_quotes(tickers, FINNHUB_API_KEY)
        if df.empty:
            st.warning(f"{index_name} ì¢…ëª© ë°ì´í„° ë¡œë”© ì‹¤íŒ¨. Finnhub í‚¤, ë ˆì´íŠ¸ë¦¬ë°‹ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            continue

        # ì‹œê°€ì´ì•¡ ìˆœì„œ ìœ ì§€ (INDEX_TOP10 ìˆœì„œ ê·¸ëŒ€ë¡œ)
        df["ì •ë ¬"] = df["ì¢…ëª©"].apply(
            lambda x: next((i for i, t in enumerate(tickers) if t in x), 999)
        )
        df = df.sort_values("ì •ë ¬").drop(columns="ì •ë ¬")

        st.dataframe(
            df.style.format({
                "ê°€ê²©": "{:,.2f}",
                "ë“±ë½(USD)": "{:+.2f}",
                "ë“±ë½ë¥ (%)": "{:+.2f}",
                "ê³ ê°€": "{:,.2f}",
                "ì €ê°€": "{:,.2f}",
            }),
            use_container_width=True,
        )
